{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ab948359d104b2181919093df65b060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad3d328c74ba45828ec38e68377cad28",
              "IPY_MODEL_9c1f3f1074c147afa4c30a561ffcec54",
              "IPY_MODEL_04460fa2578441bcb10e87fe9b766afc"
            ],
            "layout": "IPY_MODEL_90eb9844af2148358ade6238139d8d94"
          }
        },
        "ad3d328c74ba45828ec38e68377cad28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157f21d20e27494db1c592992f8b1da9",
            "placeholder": "​",
            "style": "IPY_MODEL_49868b23d816429ba397389416f7c382",
            "value": "Map: 100%"
          }
        },
        "9c1f3f1074c147afa4c30a561ffcec54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df0a53bb102463fa82443717221d85c",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0dd438767dd479a86c4cb8284f9e839",
            "value": 10000
          }
        },
        "04460fa2578441bcb10e87fe9b766afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f55139932e74592be0a44f30df39fc6",
            "placeholder": "​",
            "style": "IPY_MODEL_c188de12254a46fbaf238ad2386c295f",
            "value": " 10000/10000 [00:07&lt;00:00, 1403.31 examples/s]"
          }
        },
        "90eb9844af2148358ade6238139d8d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "157f21d20e27494db1c592992f8b1da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49868b23d816429ba397389416f7c382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df0a53bb102463fa82443717221d85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dd438767dd479a86c4cb8284f9e839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f55139932e74592be0a44f30df39fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c188de12254a46fbaf238ad2386c295f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpJwVRy76lWe",
        "outputId": "1c22e018-f37e-442b-b8ff-82383568227c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets pandas torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments,Trainer, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "YjwliB9j6sYf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing and loading dataset"
      ],
      "metadata": {
        "id": "88wGA89162JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('small_talk_moody_teen_dataset.csv')\n",
        "print(f\"Loaded {len(df)} conversation pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWCTgiWJ65Hd",
        "outputId": "22bddb39-1256-41ea-b8de-fe3ae61965bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2500 conversation pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "\n",
        "# Lowercase version\n",
        "df_lower = df.copy()\n",
        "df_lower[\"user_utterance\"] = df_lower[\"user_utterance\"].str.lower()\n",
        "\n",
        "# Titlecase version\n",
        "df_title = df.copy()\n",
        "df_title[\"user_utterance\"] = df_title[\"user_utterance\"].str.title()\n",
        "\n",
        "# Uppercase version\n",
        "df_upper = df.copy()\n",
        "df_upper[\"user_utterance\"] = df_upper[\"user_utterance\"].str.upper()\n",
        "\n",
        "# Combine all versions and remove duplicates\n",
        "df_augmented = pd.concat([df, df_lower, df_title, df_upper], ignore_index=True)\n",
        "print(f\"Original dataset: {len(df)} rows\")\n",
        "print(f\"Augmented dataset: {len(df_augmented)} rows\")\n",
        "df_augmented.head(), df_augmented.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llb2_tPa7I-S",
        "outputId": "4692cb23-9d42-471b-f65a-95bd1e66d3b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset: 2500 rows\n",
            "Augmented dataset: 10000 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            user_utterance                                       bot_response\n",
              " 0          You sound upset  I am real enough to be tired of this question....\n",
              " 1                       Hi  Yeah, hi. I am here, not thrilled, but present...\n",
              " 2         Nice to meet you  Hello. Let us get this over with. Say what you...\n",
              " 3                       Hi  Morning, I guess. I did not sleep, again. Can ...\n",
              " 4  Tell me something silly  Sure, a joke: I walked into a bar and immediat...,\n",
              "              user_utterance                                       bot_response\n",
              " 9995  DO YOU HAVE FEELINGS?  I tolerate music and people in small doses. Bo...\n",
              " 9996           YOU ARE SLOW  Got it. I will dial it down. You can dial down...\n",
              " 9997          ARE YOU OKAY?  Yeah, I am moody. It is not a glitch, it is a ...\n",
              " 9998       MUCH APPRECIATED  Sure. It was not exactly hard. Next time try n...\n",
              " 9999              NICE WORK  Cool. Validation received. Let us keep expecta...)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialising tokeniser and model"
      ],
      "metadata": {
        "id": "R6hb93rR7fM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gpt2' # Using gpt2(small)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ZvXJXR7icx",
        "outputId": "c877cf5a-49e4-492f-c441-24c05c226edf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add padding token because gpt2 doesn't have one default\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "YXQGLJwj7mum"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting data for fine-tuning"
      ],
      "metadata": {
        "id": "V0UJdJuH71HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create conversational format: \"Human: {prompt}\\nBot: {response}<|endoftext|>\"\n",
        "def format_conversation(row):\n",
        "    return f\"Human: {row['user_utterance']}\\nBot: {row['bot_response']}{tokenizer.eos_token}\"\n",
        "\n",
        "df_augmented['text'] = df_augmented.apply(format_conversation, axis=1)\n",
        "df_augmented.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SA4Y9XEW73vK",
        "outputId": "11df13ba-f861-42a1-c1ca-c7d8ff037a10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            user_utterance                                       bot_response  \\\n",
              "0          You sound upset  I am real enough to be tired of this question....   \n",
              "1                       Hi  Yeah, hi. I am here, not thrilled, but present...   \n",
              "2         Nice to meet you  Hello. Let us get this over with. Say what you...   \n",
              "3                       Hi  Morning, I guess. I did not sleep, again. Can ...   \n",
              "4  Tell me something silly  Sure, a joke: I walked into a bar and immediat...   \n",
              "\n",
              "                                                text  \n",
              "0  Human: You sound upset\\nBot: I am real enough ...  \n",
              "1  Human: Hi\\nBot: Yeah, hi. I am here, not thril...  \n",
              "2  Human: Nice to meet you\\nBot: Hello. Let us ge...  \n",
              "3  Human: Hi\\nBot: Morning, I guess. I did not sl...  \n",
              "4  Human: Tell me something silly\\nBot: Sure, a j...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-283160c7-dc7a-4e1c-82c1-c523d257a723\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_utterance</th>\n",
              "      <th>bot_response</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You sound upset</td>\n",
              "      <td>I am real enough to be tired of this question....</td>\n",
              "      <td>Human: You sound upset\\nBot: I am real enough ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi</td>\n",
              "      <td>Yeah, hi. I am here, not thrilled, but present...</td>\n",
              "      <td>Human: Hi\\nBot: Yeah, hi. I am here, not thril...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nice to meet you</td>\n",
              "      <td>Hello. Let us get this over with. Say what you...</td>\n",
              "      <td>Human: Nice to meet you\\nBot: Hello. Let us ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi</td>\n",
              "      <td>Morning, I guess. I did not sleep, again. Can ...</td>\n",
              "      <td>Human: Hi\\nBot: Morning, I guess. I did not sl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tell me something silly</td>\n",
              "      <td>Sure, a joke: I walked into a bar and immediat...</td>\n",
              "      <td>Human: Tell me something silly\\nBot: Sure, a j...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-283160c7-dc7a-4e1c-82c1-c523d257a723')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-283160c7-dc7a-4e1c-82c1-c523d257a723 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-283160c7-dc7a-4e1c-82c1-c523d257a723');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-312bde51-343e-4e1a-a6a0-1e10a958946e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-312bde51-343e-4e1a-a6a0-1e10a958946e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-312bde51-343e-4e1a-a6a0-1e10a958946e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_augmented",
              "summary": "{\n  \"name\": \"df_augmented\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"user_utterance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 266,\n        \"samples\": [\n          \"You Are Annoying\",\n          \"okay\",\n          \"Nice To Meet You\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bot_response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"If you want better, ask better. Otherwise you are just heckling from the cheap seats.\",\n          \"I tolerate music and people in small doses. Both get loud for no reason. That answer your question?\",\n          \"That sounds familiar. Most days are a fog and the rest are noise. If you want to talk, talk, but do not expect miracles.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1122,\n        \"samples\": [\n          \"Human: YOU ARE COOL\\nBot: That is nice of you to say. I am still a program with chronic indifference.<|endoftext|>\",\n          \"Human: No Thanks\\nBot: That is fine. I was not emotionally invested anyway. We can drop it.<|endoftext|>\",\n          \"Human: Today has been great\\nBot: Rough day tracks. Everything feels heavier lately. Say what you need to say and we will move on.<|endoftext|>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenising the dataset"
      ],
      "metadata": {
        "id": "DSxgAmLM8B1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding='max_length'\n",
        "    )"
      ],
      "metadata": {
        "id": "kJWOHD1h8k0D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to HuggingFace dataset\n",
        "dataset = Dataset.from_pandas(df_augmented[['text']])\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['text']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1ab948359d104b2181919093df65b060",
            "ad3d328c74ba45828ec38e68377cad28",
            "9c1f3f1074c147afa4c30a561ffcec54",
            "04460fa2578441bcb10e87fe9b766afc",
            "90eb9844af2148358ade6238139d8d94",
            "157f21d20e27494db1c592992f8b1da9",
            "49868b23d816429ba397389416f7c382",
            "1df0a53bb102463fa82443717221d85c",
            "e0dd438767dd479a86c4cb8284f9e839",
            "5f55139932e74592be0a44f30df39fc6",
            "c188de12254a46fbaf238ad2386c295f"
          ]
        },
        "id": "pKCeBZj18reB",
        "outputId": "d4b18143-c8e1-4312-abbc-1e14fe1225cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ab948359d104b2181919093df65b060"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting dataset"
      ],
      "metadata": {
        "id": "LL2VVgfI9EdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting 90% train, 10% test\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)"
      ],
      "metadata": {
        "id": "T6sCbWS99GAH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collector"
      ],
      "metadata": {
        "id": "3TwqYOTv9R9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # We're doing causal language modeling, not masked\n",
        ")"
      ],
      "metadata": {
        "id": "9bKKgiZZ9T10"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure training arguments"
      ],
      "metadata": {
        "id": "lL9kz2Ci9XiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./moody_gpt2',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    eval_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    save_steps=500,\n",
        "    save_total_limit=1,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
        "    report_to='none'\n",
        ")"
      ],
      "metadata": {
        "id": "Svi3RJA29Y77"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialise trainer"
      ],
      "metadata": {
        "id": "sEVb_MaY9fK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split_dataset['train'],\n",
        "    eval_dataset=split_dataset['test'],\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "Xf5Y37gi9g7Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "PjC8AEY89hnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "upXvlSWo9mUT",
        "outputId": "299ad9d7-3623-45d3-d671-7885e754d3d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5625/5625 59:09, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.345805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.330500</td>\n",
              "      <td>0.279062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.286400</td>\n",
              "      <td>0.258515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.268900</td>\n",
              "      <td>0.258427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.265100</td>\n",
              "      <td>0.252182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.257800</td>\n",
              "      <td>0.247486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.252500</td>\n",
              "      <td>0.248425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.253200</td>\n",
              "      <td>0.248359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.253200</td>\n",
              "      <td>0.245607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.251300</td>\n",
              "      <td>0.243722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.243048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.251300</td>\n",
              "      <td>0.242144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.245500</td>\n",
              "      <td>0.242689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.243900</td>\n",
              "      <td>0.241895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.247100</td>\n",
              "      <td>0.240948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.243900</td>\n",
              "      <td>0.240498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.244500</td>\n",
              "      <td>0.240658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.244300</td>\n",
              "      <td>0.239349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.241000</td>\n",
              "      <td>0.238192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.242300</td>\n",
              "      <td>0.239477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.238765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.238400</td>\n",
              "      <td>0.236608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.240500</td>\n",
              "      <td>0.235726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.236300</td>\n",
              "      <td>0.235513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.238900</td>\n",
              "      <td>0.235761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.242000</td>\n",
              "      <td>0.235807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.233400</td>\n",
              "      <td>0.235138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.236100</td>\n",
              "      <td>0.234567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5625, training_loss=0.30571639489067925, metrics={'train_runtime': 3551.649, 'train_samples_per_second': 12.67, 'train_steps_per_second': 1.584, 'total_flos': 1.175814144e+16, 'train_loss': 0.30571639489067925, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "NqExV0rJChG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./moody_gpt2')\n",
        "tokenizer.save_pretrained('./moody_gpt2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAmG9n-3Cimh",
        "outputId": "6f3e3478-7264-4b0a-edb3-ea37736154f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./moody_gpt2/tokenizer_config.json',\n",
              " './moody_gpt2/special_tokens_map.json',\n",
              " './moody_gpt2/vocab.json',\n",
              " './moody_gpt2/merges.txt',\n",
              " './moody_gpt2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "5V00OjFxBjcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model_path = './moody_gpt2'\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Set padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Move to device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhS1LyxtBlgJ",
        "outputId": "90025564-afdc-47b5-abf6-bc79a08f222a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate response"
      ],
      "metadata": {
        "id": "sjLHYTL99msE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, max_length=100):\n",
        "    model.eval()\n",
        "    input_text = f\"Human: {prompt}\\nBot:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.8,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            repetition_penalty=1.2,\n",
        "            no_repeat_ngram_size=3\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    bot_response = response.split('Bot:')[-1].strip()\n",
        "\n",
        "    # Split into sentences\n",
        "    import re\n",
        "    sentences = re.split(r'([.!?])', bot_response)\n",
        "\n",
        "    # Reconstruct complete sentences (text + punctuation)\n",
        "    complete_sentences = []\n",
        "    for i in range(0, len(sentences)-1, 2):\n",
        "        if i+1 < len(sentences) and sentences[i].strip():\n",
        "            complete_sentences.append(sentences[i] + sentences[i+1])\n",
        "\n",
        "    # Keep only first 2 sentences\n",
        "    if len(complete_sentences) >= 2:\n",
        "        result = ''.join(complete_sentences[:2]).strip()\n",
        "    elif len(complete_sentences) == 1:\n",
        "        result = complete_sentences[0].strip()\n",
        "    else:\n",
        "        # If no complete sentence, add period\n",
        "        result = bot_response + '.' if bot_response else \"I'm not sure how to respond.\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "AFl_P5wV_lBU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "URE4O47a_puv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Testing Fine-tuned Model ---\")\n",
        "test_prompts = [\n",
        "    \"How was school today?\",\n",
        "    \"Want to hang out?\",\n",
        "    \"You seem upset, what's wrong?\"\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Human: {prompt}\")\n",
        "    print(f\"Bot: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auRYY8mC_qov",
        "outputId": "b9ea7687-7b96-4c01-fe61-4265ed6118f8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Fine-tuned Model ---\n",
            "Human: How was school today?\n",
            "Bot: Evening. I am not feeling chatty, but I can manage a conversation.\n",
            "\n",
            "Human: Want to hang out?\n",
            "Bot: Evening. I am not feeling chatty, but I can manage a conversation.\n",
            "\n",
            "Human: You seem upset, what's wrong?\n",
            "Bot: I talk like this because pretending to be excited is exhausting. Honesty is faster.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to download directory for colab. Uncomment to download the model directory\n",
        "# from google.colab import files\n",
        "\n",
        "# !zip -r /content/small_talk_model.zip /content/moody_gpt2\n",
        "\n",
        "# files.download('/content/small_talk_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "INDsj-VidBdZ",
        "outputId": "e959c78e-8c24-42b3-8074-374dfbf6d6a9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/moody_gpt2/ (stored 0%)\n",
            "updating: content/moody_gpt2/vocab.json (deflated 68%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/ (stored 0%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/vocab.json (deflated 68%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/merges.txt (deflated 53%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/rng_state.pth (deflated 26%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/scheduler.pt (deflated 62%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/scaler.pt (deflated 64%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/special_tokens_map.json (deflated 74%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/model.safetensors (deflated 7%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/training_args.bin (deflated 54%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/trainer_state.json (deflated 81%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/tokenizer_config.json (deflated 56%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/config.json (deflated 52%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/generation_config.json (deflated 24%)\n",
            "updating: content/moody_gpt2/checkpoint-5625/optimizer.pt (deflated 8%)\n",
            "updating: content/moody_gpt2/merges.txt (deflated 53%)\n",
            "updating: content/moody_gpt2/special_tokens_map.json (deflated 74%)\n",
            "updating: content/moody_gpt2/model.safetensors (deflated 7%)\n",
            "updating: content/moody_gpt2/tokenizer_config.json (deflated 56%)\n",
            "updating: content/moody_gpt2/config.json (deflated 52%)\n",
            "updating: content/moody_gpt2/generation_config.json (deflated 24%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34e870df-133c-4b0e-953a-f3b4ac6c6cb2\", \"small_talk_model.zip\", 1844442446)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interactive loop"
      ],
      "metadata": {
        "id": "sAkcK_Ozb1Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def chat():\n",
        "#     print(\"Chatbot: Hello! I'm ready to chat. Type 'bye' to exit.\\n\")\n",
        "\n",
        "#     while True:\n",
        "#         # Get user input\n",
        "#         user_input = input(\"You: \").strip()\n",
        "\n",
        "#         # Check for exit condition\n",
        "#         if user_input.lower() == 'bye':\n",
        "#             print(\"Chatbot: Goodbye! Have a great day!\")\n",
        "#             break\n",
        "\n",
        "#         # Skip empty inputs\n",
        "#         if not user_input:\n",
        "#             continue\n",
        "\n",
        "#         # Generate and display response\n",
        "#         response = generate_response(user_input)\n",
        "#         print(f\"Chatbot: {response}\\n\")\n",
        "\n",
        "# # Start the chat\n",
        "# chat()"
      ],
      "metadata": {
        "id": "C7DGt7SKb4a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Wx9Ax0CcFC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}